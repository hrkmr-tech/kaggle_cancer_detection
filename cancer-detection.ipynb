{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# CNN Cancer Detection Kaggle Mini-Project\n\nThe goal of this project is to classify images into two groups (cancer and non-cancer) or calculate the probability from them.\n\nGitHub: https://github.com/hrkmr-tech/kaggle_cancer_detection","metadata":{"_uuid":"a6717103051c3f8b781161d917a4fe7352be60e4"}},{"cell_type":"markdown","source":"## Importing Libraries\nFirst, we will import the libraries to use in this project.","metadata":{"_uuid":"143ed018a1cfecf3438504b2b0d1a63beb053057"}},{"cell_type":"code","source":"from glob import glob \nimport numpy as np\nimport pandas as pd\nimport keras, cv2, os\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\n\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\n\nimport gc","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-02T08:12:29.740501Z","iopub.execute_input":"2022-06-02T08:12:29.740774Z","iopub.status.idle":"2022-06-02T08:12:32.690619Z","shell.execute_reply.started":"2022-06-02T08:12:29.740725Z","shell.execute_reply":"2022-06-02T08:12:32.689872Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Data\n\nNow, we will load the data from the path. We can get the id of data from the filename.","metadata":{"_uuid":"cc88d74857744a4a559f7457caa6b3d8dd8fe958"}},{"cell_type":"code","source":"train_path = '../input/train/'\ntest_path = '../input/test/'\nlabel_path = '../input/train_labels.csv'\n\ndf = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))})\ndf['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\nlabels = pd.read_csv(label_path)\n\nprint(\"the number of samples is: {}\".format(df.shape[0]))","metadata":{"_uuid":"d72f6d8131277d5a1452d92677bcaaae8117165b","execution":{"iopub.status.busy":"2022-06-02T08:12:32.692065Z","iopub.execute_input":"2022-06-02T08:12:32.692380Z","iopub.status.idle":"2022-06-02T08:12:37.855621Z","shell.execute_reply.started":"2022-06-02T08:12:32.692324Z","shell.execute_reply":"2022-06-02T08:12:37.854717Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Merging the labels and ids\n\nThe labels and ids are combined here so that we can use it to train a model.","metadata":{}},{"cell_type":"code","source":"# merge all id, path and label\ndf = df.merge(labels, on = \"id\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T08:12:37.856934Z","iopub.execute_input":"2022-06-02T08:12:37.857475Z","iopub.status.idle":"2022-06-02T08:12:38.147109Z","shell.execute_reply.started":"2022-06-02T08:12:37.857418Z","shell.execute_reply":"2022-06-02T08:12:38.146429Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Loading the images\n\nNow, we will load some images to explore the data. ","metadata":{"_uuid":"e32d37b60a88fb0c038ab2a6938bd46198e79740"}},{"cell_type":"code","source":"# Load 10,000 images\nN=10000\n\nX = np.zeros([N,96,96,3],dtype=np.uint8) \ny = np.squeeze(df.as_matrix(columns=['label']))[0:N]\nfor i, row in tqdm_notebook(df.iterrows(), total=N):\n    if i == N:\n        break\n    # reading images\n    X[i] = cv2.imread(row['path'])","metadata":{"_uuid":"d2207ea4a34a42c5173b48e4ba90403fe75d6685","execution":{"iopub.status.busy":"2022-06-02T08:12:38.148490Z","iopub.execute_input":"2022-06-02T08:12:38.148766Z","iopub.status.idle":"2022-06-02T08:13:46.084197Z","shell.execute_reply.started":"2022-06-02T08:12:38.148718Z","shell.execute_reply":"2022-06-02T08:13:46.083455Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)\n\nWe will do three things for EDA. \n\n1. Showing some images\n1. Checking the ratio of classes\n1. Exploring the characteristics","metadata":{"_uuid":"50a761bd5a4be83eaf540f7602ba8e5a713d59f2"}},{"cell_type":"markdown","source":"### Showing some images\n\nSome images are shown to check what kinds of images are in the data.","metadata":{}},{"cell_type":"code","source":"def convert_to_label(val):\n    return 'cancer' if val == 1 else 'not cancer'\n\n# pick up some images\nidx = [0, 100, 200, 300, 400]\nfor i in idx:\n    plt.imshow(X[i])\n    plt.title(convert_to_label(y[i]))\n    plt.show()","metadata":{"_uuid":"ffed68f7b732222097006f1047744950ad085ed8","execution":{"iopub.status.busy":"2022-06-02T08:13:46.087457Z","iopub.execute_input":"2022-06-02T08:13:46.087690Z","iopub.status.idle":"2022-06-02T08:13:47.197145Z","shell.execute_reply.started":"2022-06-02T08:13:46.087644Z","shell.execute_reply":"2022-06-02T08:13:47.196163Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Checking the ratio of classes\n\nWe will check the ratio of classes. If the number of each class is radically unbalanced, we have to correct the ratio in order to train a better model.","metadata":{"_uuid":"7931e9a388a07450ae4a9576dd31ee72aea86ccc"}},{"cell_type":"code","source":"# I found this nice shorthand here. https://stackoverflow.com/a/37060037\npositive_numbers = (y==1).sum()\nnegative_numbers = (y==0).sum()\n\n\nplt.bar([0,1], [negative_numbers, positive_numbers]) #plot a bar chart of the label frequency\nplt.xticks([0,1],[\"Negative (N={})\".format(negative_numbers),\"Positive (N={})\".format(positive_numbers)])\nplt.ylabel(\"the number of samples\")","metadata":{"_uuid":"9c0351062237909773100c6e87409fe270379652","execution":{"iopub.status.busy":"2022-06-02T08:13:47.202734Z","iopub.execute_input":"2022-06-02T08:13:47.204652Z","iopub.status.idle":"2022-06-02T08:13:47.439986Z","shell.execute_reply.started":"2022-06-02T08:13:47.203014Z","shell.execute_reply":"2022-06-02T08:13:47.439074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"The ratio is around 60 vs 40. This is not much a problem because the number of the samples at hand is relatively large (220,025 samples). ","metadata":{"_uuid":"529ea0bdfc9338af404172c436c9a34bf7ab6b2d"}},{"cell_type":"markdown","source":"### Exploring the characteristics\n\nWe will split the data into the two classes to compare the characteristics of each class.","metadata":{}},{"cell_type":"code","source":"positive_samples = X[y == 1]\nnegative_samples = X[y == 0]","metadata":{"_uuid":"6e4d8e67e64d2cdc6ad4098b4a67f93c87d9ec5d","execution":{"iopub.status.busy":"2022-06-02T08:13:47.445906Z","iopub.execute_input":"2022-06-02T08:13:47.446492Z","iopub.status.idle":"2022-06-02T08:13:47.665889Z","shell.execute_reply.started":"2022-06-02T08:13:47.446315Z","shell.execute_reply":"2022-06-02T08:13:47.665138Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Now, we will compare the distribution of pixel values for each of RGB.","metadata":{"_uuid":"c38d6b1820db94afb9dabf3b29f407bec119830e"}},{"cell_type":"code","source":"nr_of_bins = 256\nfig,axs = plt.subplots(3,2,sharey=True,figsize=(8,8),dpi=150)\n\n#RGB channels\naxs[0,0].hist(negative_samples[:,:,:,0].flatten(),bins=nr_of_bins,density=True)\naxs[0,1].hist(positive_samples[:,:,:,0].flatten(),bins=nr_of_bins,density=True)\naxs[1,0].hist(negative_samples[:,:,:,1].flatten(),bins=nr_of_bins,density=True)\naxs[1,1].hist(positive_samples[:,:,:,1].flatten(),bins=nr_of_bins,density=True)\naxs[2,0].hist(negative_samples[:,:,:,2].flatten(),bins=nr_of_bins,density=True)\naxs[2,1].hist(positive_samples[:,:,:,2].flatten(),bins=nr_of_bins,density=True)\n\n#Set image labels\naxs[0,0].set_title(\"Negative samples (N = {})\".format(negative_samples.shape[0]))\naxs[0,1].set_title(\"Positive samples (N = {})\".format(positive_samples.shape[0]))\naxs[0,1].set_ylabel(\"R\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[1,1].set_ylabel(\"G\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[2,1].set_ylabel(\"B\",rotation='horizontal',labelpad=35,fontsize=12)\nfor i in range(3):\n    axs[i,0].set_ylabel(\"frequency\")\naxs[2,1].set_xlabel(\"the value of color element\")\naxs[2,0].set_xlabel(\"the value of color element\")\nfig.tight_layout()","metadata":{"_uuid":"9f0907419bd54f6cae17a469cd054a801db3fdb5","execution":{"iopub.status.busy":"2022-06-02T08:13:47.667413Z","iopub.execute_input":"2022-06-02T08:13:47.667682Z","iopub.status.idle":"2022-06-02T08:13:56.229347Z","shell.execute_reply.started":"2022-06-02T08:13:47.667636Z","shell.execute_reply":"2022-06-02T08:13:56.228463Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"We can know that from the histgrams:\n* the negative samples have the higher frequency of large values in each of the colors.","metadata":{"_uuid":"64979c39dddf575f01912a9b733f0c39fbdae155"}},{"cell_type":"code","source":"nr_of_bins = 64 #we use a bit fewer bins to get a smoother image\nfig,axs = plt.subplots(1,2,sharey=True, sharex = True, figsize=(8,2),dpi=150)\naxs[0].hist(np.mean(negative_samples,axis=(1,2,3)),bins=nr_of_bins,density=True)\naxs[1].hist(np.mean(positive_samples,axis=(1,2,3)),bins=nr_of_bins,density=True)\naxs[0].set_title(\"Negative samples\")\naxs[1].set_title(\"Positive samples\")\naxs[0].set_xlabel(\"mean brightness\")\naxs[1].set_xlabel(\"mean brightness\")\naxs[0].set_ylabel(\"frequency\")\naxs[1].set_ylabel(\"frequency\")","metadata":{"_uuid":"296e1bf788a2ee4f48358f42cfc22a2117870e00","execution":{"iopub.status.busy":"2022-06-02T08:13:56.230433Z","iopub.execute_input":"2022-06-02T08:13:56.230732Z","iopub.status.idle":"2022-06-02T08:13:57.404774Z","shell.execute_reply.started":"2022-06-02T08:13:56.230693Z","shell.execute_reply":"2022-06-02T08:13:57.403936Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"There is an obvious difference pretty obvious differenes between the positive and negative samples:\n* the distribution of the brightness from the negative samples have two edges, while that from the positive ones have one edge","metadata":{"_uuid":"3671a84db204421a58fca08010e38a99490b1e27"}},{"cell_type":"code","source":"# memory release\npositives_samples = None\nnegative_samples = None\ngc.collect()","metadata":{"_uuid":"e14b07edae9d62cc873b1b10c5288c72bfbf9671","execution":{"iopub.status.busy":"2022-06-02T08:13:57.409407Z","iopub.execute_input":"2022-06-02T08:13:57.411799Z","iopub.status.idle":"2022-06-02T08:13:57.549033Z","shell.execute_reply.started":"2022-06-02T08:13:57.411723Z","shell.execute_reply":"2022-06-02T08:13:57.548105Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Creating the model\n\n### Defining the Model\nHere is the definition of our model. We'll try to achive 80% accuracy against the validation data. ","metadata":{"_uuid":"c3bd89f6d9e00472c46b1c9c617e3d090c9fccce"}},{"cell_type":"code","source":"# the definition of hyperparameters\nkernel_size = (3,3)\npool_size= (2,2)\nfilter_1 = 32\nfilter_2 = 64\nfilter_3 = 128\ndropout_conv = 0.3\ndropout_dense = 0.5\n\n# creating the model\nmodel = Sequential()\n\n# 1st convolusion layer\nmodel.add(Conv2D(filter_1, kernel_size, input_shape = (96, 96, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\n# 2nd convolusion layer\nmodel.add(Conv2D(filter_2, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n# 3rd convolusion layer\nmodel.add(Conv2D(filter_3, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n# dense layer\nmodel.add(Flatten())\nmodel.add(Dense(256, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(dropout_dense))\n\n# output 0 or 1\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.001), \n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"_uuid":"9434b86b47f6132843b328d4fbf326aad01b24c0","execution":{"iopub.status.busy":"2022-06-02T08:13:57.550628Z","iopub.execute_input":"2022-06-02T08:13:57.552344Z","iopub.status.idle":"2022-06-02T08:13:59.603872Z","shell.execute_reply.started":"2022-06-02T08:13:57.551057Z","shell.execute_reply":"2022-06-02T08:13:59.603102Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Loading all the train data\nWe will train a model with all the data. As we checked it brefore, the unbalanced ratio of the classes is not a big problem because of the large samples.","metadata":{"_uuid":"c23406dd90b311f7683e6d5b76a5c929d8d52bc4"}},{"cell_type":"code","source":"N = df.shape[0] \n\nX = np.zeros([N,96,96,3],dtype=np.uint8) \ny = np.squeeze(df.as_matrix(columns=['label']))[0:N]\nfor i, row in tqdm_notebook(df.iterrows(), total=N):\n    if i == N:\n        break\n    X[i] = cv2.imread(row['path'])","metadata":{"_uuid":"594a0db99d65d223695d4dd8d9437d915363e055","execution":{"iopub.status.busy":"2022-06-02T08:13:59.609710Z","iopub.execute_input":"2022-06-02T08:13:59.609964Z","iopub.status.idle":"2022-06-02T08:38:48.939217Z","shell.execute_reply.started":"2022-06-02T08:13:59.609919Z","shell.execute_reply":"2022-06-02T08:38:48.938397Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Training the Model\nFinally, we will train the model.\n\n* batch_size: `50`\n* epochs: `5`\n* validation_split: `0.2`","metadata":{"_uuid":"cd873cb97936e734aca949c2dc7673b53cbcaa8d"}},{"cell_type":"code","source":"batch_size = 50\nepochs = 3\nvalidation_split = 0.2\n\nval_count = int(np.round(validation_split * y.shape[0]))\niterations = np.floor(val_count / batch_size).astype(int)\n\nfor epoch in range(epochs):\n    iterations = np.floor(val_count / batch_size).astype(int)\n    loss = 0\n    acc = 0\n    for i in range(iterations):\n        start_idx = i * batch_size\n        x_batch = X[start_idx:start_idx+batch_size]\n        y_batch = y[start_idx:start_idx+batch_size]\n        \n        # training a model\n        stat = model.train_on_batch(x_batch, y_batch)\n\n        loss = loss + stat[0]\n        acc = acc + stat[1]\n        \nprint(\"train loss: {}\".format(loss / iterations))\nprint(\"train acc: {}\".format(acc / iterations))\n\niterations = np.floor((y.shape[0] - val_count) / batch_size).astype(int)\n\nfor i in range(iterations):\n    start_idx = i * batch_size\n    x_batch = X[start_idx:start_idx+batch_size]\n    y_batch = y[start_idx:start_idx+batch_size]\n    \n    # test\n    stat = model.test_on_batch(x_batch, y_batch)\n\n    loss = loss + stat[0]\n    acc = acc + stat[1]\n        \nprint(\"validation loss: {}\".format(loss / iterations))\nprint(\"validation acc: {}\".format(acc / iterations))","metadata":{"_uuid":"86b62f51aaedb77b00bfc39a830cd256c7c826d3","execution":{"iopub.status.busy":"2022-06-02T08:38:48.940766Z","iopub.execute_input":"2022-06-02T08:38:48.941044Z","iopub.status.idle":"2022-06-02T08:40:09.598241Z","shell.execute_reply.started":"2022-06-02T08:38:48.940994Z","shell.execute_reply":"2022-06-02T08:40:09.597439Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# memory release\nX = None\ny = None\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T08:40:09.599561Z","iopub.execute_input":"2022-06-02T08:40:09.600070Z","iopub.status.idle":"2022-06-02T08:40:09.771544Z","shell.execute_reply.started":"2022-06-02T08:40:09.600017Z","shell.execute_reply":"2022-06-02T08:40:09.769637Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Submission\nSubmitting the final result against the test data.","metadata":{"_uuid":"4726acfd86e61d1ad1c65fa0793204c2b128aafc"}},{"cell_type":"code","source":"test_files = glob(os.path.join(test_path,'*.tif'))\n\nbatch_size = 3000\nmax_idx = len(test_files)\n\nsubmission = pd.DataFrame()\nfor idx in range(0, max_idx, batch_size):\n    test_data = pd.DataFrame({'path': test_files[idx:idx+batch_size]})\n    # get id from the filename\n    test_data['id'] = test_data['path'].map(lambda x: x.split('/')[3].split(\".\")[0])\n    test_data['image'] = test_data['path'].map(cv2.imread)\n    K_test = np.stack(test_data[\"image\"].values)\n    # prediction\n    test_data['label'] = model.predict(K_test,verbose = 1)\n    submission = pd.concat([submission, test_data[[\"id\", \"label\"]]])\n\n# showing the result\nsubmission.head()","metadata":{"_uuid":"6d5d71c896efb4018434d00d1aab03d3355cb367","execution":{"iopub.status.busy":"2022-06-02T08:40:09.778419Z","iopub.execute_input":"2022-06-02T08:40:09.781717Z","iopub.status.idle":"2022-06-02T08:47:46.282676Z","shell.execute_reply.started":"2022-06-02T08:40:09.781654Z","shell.execute_reply":"2022-06-02T08:47:46.281930Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False, header = True)","metadata":{"_uuid":"a6113e9f267e0902a423490b75fa331f524e2aae","execution":{"iopub.status.busy":"2022-06-02T08:47:46.284113Z","iopub.execute_input":"2022-06-02T08:47:46.284441Z","iopub.status.idle":"2022-06-02T08:47:46.759168Z","shell.execute_reply.started":"2022-06-02T08:47:46.284387Z","shell.execute_reply":"2022-06-02T08:47:46.758380Z"},"trusted":true},"execution_count":16,"outputs":[]}]}